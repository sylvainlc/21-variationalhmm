\documentclass{article}


\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{authblk,url}
\usepackage{amssymb,amsmath,amsthm,twoopt,xargs,mathtools,dsfont}
\usepackage{times,ifthen}
\usepackage{fancyhdr,xcolor}
\usepackage{hyperref}

\newtheorem{axiom}{Axiom}
\newtheorem{claim}[axiom]{Claim}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}


\newcommand{\parvar}{\varphi}
\newcommand{\parvarspace}{\Phi}
\newcommand{\vd}[1]{q_{\parvar,#1}} % Density


\title{Backward variational inference for hidden Markov models}
\date{}

%\author[$\wr$]{Mathis Chagneux}
\author[$\dag$]{XXX}
%\affil[$\wr$]{{\small LTCI, T\'el\'ecom Paris, Institut Polytechnique de Paris, Palaiseau.}}

\affil[$\dag$]{{\small }}

\lhead{}
\rhead{}

\DeclareUnicodeCharacter{2212}{-}
\usepackage{geometry}
\pagestyle{fancy}


\newcommand{\retrokmodnorm}{\bar{\boldsymbol{\mathcal{L}}}^{\precpar}}
\newcommand{\xarb}{x^\ast}
\newcommand{\precparsp}{\mathcal{E}}
\newcommand{\fk}[2]{\mathbf{F}_{#1 | #2}}
\newcommand{\probmeas}[1]{\mathsf{M}_1(#1)}
\newcommand{\Xfd}{\mathcal{X}}
\newcommand{\uksymbol}{\ell}
\newcommandx{\bkmod}[2][1=]{ 
\ifthenelse{\equal{#1}{}}
{\kernel{B}_{#2}^\precpar}
{\kernel{B}_{#2}^\precpar}
}

\newcommand{\cev}[1]{\reflectbox{\ensuremath{\vec{\reflectbox{\ensuremath{#1}}}}}}
\newcommand{\ukmod}[1]{\mathbf{L}_{#1}^\precpar}
\newcommand{\shiftbwd}{\cev{\shiftsymbol}^{\precpar}}
\newcommand{\shiftfwd}{\vec{\shiftsymbol}^{\, \precpar}}
\newcommand{\shiftsymbol}{\Phi}
\newcommand{\precpar}{\varphi}
\newcommand{\intvect}[2]{\{ #1, #2 \}}
\newcommandx\tstatmod[2][1=]{
\ifthenelse{\equal{#1}{}}
	{\tstatletter^{\precpar}_{#2}}
	{\tau^{\precpar}_{#2}^{#1}}
}
\newcommand{\noshift}{\shiftsymbol^{\precpar}}
\newcommand{\udlow}{\sigma_-}
\newcommand{\udup}{\sigma_+}
\newcommand{\udlowvar}{\vartheta_-}
\newcommand{\udupvar}{\vartheta_+}
\newcommand{\retrok}{\boldsymbol{\mathcal{L}}}
%\newcommand{\intvect}[2]{\llbracket #1, #2 \rrbracket}
\newcommandx{\bkw}[2][1=]{ 
\ifthenelse{\equal{#1}{}}
{\kernel{B}_{#2}}
{\kernel{B}_{#2}}
}
\newcommand{\retroknorm}{\bar{\boldsymbol{\mathcal{L}}}}
\newcommand{\ud}[1]{\uksymbol_{#1}} 
\newcommand{\nset}{\mathbb{N}}
\newcommand{\nsetpos}{\mathbb{N}_{> 0}}
\newcommand{\1}{\mathbbm{1}} 
\newcommandx{\postmod}[2][1=]{
\ifthenelse{\equal{#1}{}}
	{\phi_{#2}^\varphi}
	{\phi_{#2}^\N}
}
\newcommand{\retrokmod}{\boldsymbol{\mathcal{L}}^\precpar}
\newcommand{\uk}[1]{\mathbf{L}_{#1}}
\newcommand{\tensprod}{\otimes}
\def\dimX{d}
\def\dimY{m}
%\def\Xset{\mathsf{X}}
\newcommand{\Xset}{\mathsf{X}}
\def\Yset{\mathsf{Y}}
\newcommand{\mk}{\kernel{G}}
\newcommand{\hk}{\kernel{Q}}
\newcommand{\md}[1]{g_{#1}}
\newcommand{\SmoothFigSize}{0.27}

\newcommand{\logllh}[1]{\ell_{#1}}
\newcommand{\llh}[1]{\mathsf{L}_{#1}}
\newcommand{\testf}{\mathsf{h}}

\newcommandx\filtderiv[2][1=]{
\ifthenelse{\equal{#1}{}}
	{\eta_{#2}}
	{\eta_{#2}^\N}
}
\newcommand{\pred}[1]{\pi_{#1}}
\newcommand{\parvec}{\theta}
\newcommand{\parspace}{\Theta}
\newcommand{\tstatletter}{\kernel{T}}
%\newcommand{\retrok}{\kernel{D}}
\newcommandx\tstat[2][1=]{
\ifthenelse{\equal{#1}{}}
	{\tstatletter_{#2}}
	{\tau_{#2}^{#1}}
}
\newcommandx\tstathat[2][1=]{
\ifthenelse{\equal{#1}{}}
	{\tstatletter_{#2}}
	{\widehat{\tau}_{#2}^{#1}}
}
\newcommand{\af}[1]{h_{#1}}
\newcommand{\deriv}{\nabla_{\parvec}}

\newcommand{\kernel}[1]{\mathbf{#1}}
\newcommand{\bmf}[1]{\set{F}(#1)}
\newcommand{\set}[1]{\mathsf{#1}}

\newcommandx{\bk}[2][1=]{
\ifthenelse{\equal{#1}{}}
{\overleftarrow{\kernel{Q}}_{#2}}
{\overleftarrow{\kernel{Q}}_{#2}^{#1}}
}

\newcommandx{\bkhat}[2][1=]{
\ifthenelse{\equal{#1}{}}
{\widehat{\kernel{Q}}_{#2}}
{\widehat{\kernel{Q}}_{#2}^{#1}}
}

\newcommand{\lk}{\kernel{L}}
\newcommand{\idop}{\operatorname{id}}
\newcommand{\hd}[1]{q_{#1}}
\newcommand{\hdhat}[1]{\widehat{q}_{#1}}


\newcommandx{\addf}[2][1=]{
\ifthenelse{\equal{#1}{}}{\termletter_{#2}}{\bar{h}_{#2 | #1}}
}
\newcommand{\addfc}[1]{\underline{\termletter}_{#1}}
\newcommand{\adds}[1]{\af{#1}}
\newcommand{\term}[1]{\termletter_{#1}}
\newcommand{\termletter}{\tilde{h}}
\newcommand{\N}{N}
\newcommand{\partpred}[1]{\pi_{#1}^\N}
\newcommand{\tstattil}[2]{\tilde{\tau}_{#2}^{#1}}
\newcommandx{\K}[1][1=]{
\ifthenelse{\equal{#1}{}}{{\kletter}}{{\widetilde{\N}^{#1}}}}
\newcommand{\hkup}{\bar{\varepsilon}}
\newcommand{\bi}[3]{J_{#1}^{(#2, #3)}}
\newcommand{\bihat}[3]{\widehat{J}_{#1}^{(#2, #3)}}

\newcommand{\kletter}{\widetilde{\N}}

\def\sigmaX{\mathcal{X}}
\def\sigmaY{\mathcal{Y}}
\def\1{\mathds{1}}
\def\pE{\mathbb{E}}
\def\pP{\mathbb{P}}
\def\plim{\overset{\pP}{\longrightarrow}}
\def\dlim{\Longrightarrow}
\def\gauss{\mathcal{N}}


\newcommand{\esssup}[2][]
{\ifthenelse{\equal{#1}{}}{\left\| #2 \right\|_\infty}{\left\| #2 \right\|^2_{\infty}}}


\newcommand{\swght}[2]{\ensuremath{\omega_{#1}^{#2}}}

\newtheorem{assumptionA}{\textbf{A}\hspace{-3pt}}
\newcommand{\rset}{\ensuremath{\mathbb{R}}}
\newcommand{\iid}{i.i.d.}

\newcommand{\smwght}[3]{\tilde{\omega}_{#1|#2}^{#3}}
\newcommand{\smwghtfunc}[2]{\tilde{\omega}_{#1|#2}}

\newcommand{\smpart}[3]{\ensuremath{\tilde{\xi}_{#1|#2}^{#3}}}
\def\aux{{\scriptstyle{\mathrm{aux}}}}
\newcommand{\bdm}{\mathsf{TwoFilt}_{bdm}}
\newcommand{\fwt}{\mathsf{TwoFilt}_{fwt}}

\newcommand{\kiss}[3][]
{\ifthenelse{\equal{#1}{}}{r_{#2|#3}}
{\ifthenelse{\equal{#1}{fully}}{r^{\star}_{#2|#3}}
{\ifthenelse{\equal{#1}{smooth}}{\tilde{r}_{#2|#3}}{\mathrm{erreur}}}}}

\newcommand{\chunk}[4][]%
{\ifthenelse{\equal{#1}{}}{\ensuremath{{#2}_{#3:#4}}}{\ensuremath{#2^#1}_{#3:#4}}
}

\newcommand{\kissforward}[3][]
{\ifthenelse{\equal{#1}{}}{p_{#2}}
{\ifthenelse{\equal{#1}{fully}}{p^{\star}_{#2}}
{\ifthenelse{\equal{#1}{smooth}}{\tilde{r}_{#2}}{\mathrm{erreur}}}}}

\newcommand{\instrpostaux}[1]{\ensuremath{\upsilon_{#1}}}
\newcommandx\post[2][1=]{
\ifthenelse{\equal{#1}{}}
	{\phi_{#2}}
	{\phi_{#2}^\N}
}

\newcommandx\posthat[2][1=]{
\ifthenelse{\equal{#1}{}}
	{\widehat{\phi}_{#2}}
	{\widehat{\phi}_{#2}^\N}
}

\newcommand{\adjfunc}[4][]
{\ifthenelse{\equal{#1}{}}{\ifthenelse{\equal{#4}{}}{\vartheta_{#2|#3}}{\vartheta_{#2|#3}(#4)}}
{\ifthenelse{\equal{#1}{smooth}}{\ifthenelse{\equal{#4}{}}{\tilde{\vartheta}_{#2|#3}}{\tilde{\vartheta}_{#2|#3}(#4)}}
{\ifthenelse{\equal{#1}{fully}}{\ifthenelse{\equal{#4}{}}{\vartheta^\star_{#2|#3}}{\vartheta^\star_{#2|#3}(#4)}}{\mathrm{erreur}}}}}

\newcommand{\XinitIS}[2][]
{\ifthenelse{\equal{#1}{}}{\ensuremath{\rho_{#2}}}{\ensuremath{\check{\rho}_{#2}}}}
\newcommand{\adjfuncforward}[1]{\vartheta_{#1}}
\newcommand{\rmd}{\ensuremath{\mathrm{d}}}
\newcommand{\eqdef}{\ensuremath{:=}}
\newcommand{\eqsp}{\;}
\newcommand{\ewght}[2]{\ensuremath{\omega_{#1}^{#2}}}
\newcommand{\ewghthat}[2]{\ensuremath{\widehat{\omega}_{#1}^{#2}}}
\newcommand{\epart}[2]{\ensuremath{\xi_{#1}^{#2}}}
\newcommand{\filt}[2][]%
{%
\ifthenelse{\equal{#1}{}}{\ensuremath{\phi_{#2}}}{\ensuremath{\phi_{#1,#2}}}%
}
\newcommand{\Xinit}{\ensuremath{\chi}}
\newcommand{\sumwght}[2][]{%
\ifthenelse{\equal{#1}{}}{\ensuremath{\Omega_{#2}}}{\ensuremath{\Omega_{#2}^{(#1)}}}}
\newcommand{\sumwghthat}[2][]{%
\ifthenelse{\equal{#1}{}}{\ensuremath{\widehat{\Omega}_{#2}}}{\ensuremath{\widehat{\Omega}_{#2}^{(#1)}}}}

\newcounter{hypH}
\newenvironment{hypH}{\refstepcounter{hypH}\begin{itemize}
\item[{\bf H\arabic{hypH}}]}{\end{itemize}}

\newcommand{\marginalset}{\mathsf{U}}

\newcommand{\calF}[2]{\mathcal{F}_{#1}^{#2}}
\newcommand{\calG}[2]{\mathcal{G}_{#1}^{#2}}
\newcommand{\Uset}{\mathsf{U}}
\newcommand{\tcalF}[2]{\widetilde{\mathcal{F}}_{#1}^{#2}}
\newcommand{\tcalG}[2]{\widetilde{\mathcal{G}}_{#1}^{#2}}

\newcommand{\kernelmarg}{\mathbf{R}}

\newcommand{\pplim}{\overset{\pP}{ \underset{\N \to \infty}{\longrightarrow}}}
\newcommand{\ddlim}{\overset{\mathcal{D}}{ \underset{\N \to \infty}{\longrightarrow}}}
\newcommand{\aslim}{\overset{\pP\mathrm{-a.s.}}{ \underset{\N \to \infty}{\longrightarrow}}}

\newcommand{\qg}[1]{\ell_{#1}}
\newcommand{\hatqg}[1]{\mathsf{\ell}_{#1}}

\newcommand{\sfd}{\mathsf{d}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\e}{\text{e}}
\newcommand{\W}{\mathbf{W}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\frob}{:}
\newcommand{\rme}{\mathrm{e}}
\newcommand{\vois}{\mathcal{V}}




\newcounter{example}[section]
\newenvironment{example}[1][]{\refstepcounter{example}\par\medskip
   \noindent \textbf{Example~\theexample:} \textit{#1} \text \rmfamily}{\medskip}

\newcommand{\expect}[2]{\mathbb{E}_{#1}\left[#2\right]}
\newcommand{\gaussian}[2]{\mathcal{N}\left( #1, #2 \right)}
\newcommand{\backward}[1]{\overleftarrow{#1}}
\newcommand{\vbackward}[1]{q_{1:#1}(z_{#1}|z_{#1 + 1})}
\newcommand{\vfilt}[1]{q_{1:#1}(z_{#1})}
\newcommand{\vbackwardparam}[2]{\backward{#1}_{1:#2}^\phi}
\newcommand{\vbackwardmean}[1]{\vbackwardparam{\mu}{#1}}
\newcommand{\vbackwardcov}[1]{\vbackwardparam{\Sigma}{#1}}
\newcommand{\vfiltparam}[2]{#1_{1:#2}^\phi}
\newcommand{\vfiltmean}[1]{\vfiltparam{\mu}{#1}}
\newcommand{\vfiltcov}[1]{\vfiltparam{\Sigma}{#1}}
\newcommand{\inv}[1]{{#1}^{-1}}
\newcommand{\stateprec}{\inv{Q^\theta}}
\newcommand{\vstateprec}{\inv{Q^\phi}}
\newcommand{\quadform}[2]{#1^T #2 #1}



\newcommand{\shift}{\vartheta}
\newcommand{\bfy}{\mathbf{y}}
\newcommand{\Zset}{\mathbb{Z}}

\DeclareMathOperator*{\argmax}{arg\,max} 

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}



\section{Excess risk bound - Theorem 3 of \cite{tang21a}}
The joint smoothing distribution is given by
$$
\phi^{y_{0:T}}_{\theta,0:T|T}(x_{0:T}) \propto \chi(x_{0})g_\theta^{y_0}(x_0) \prod_{t=1}^Tm_\theta(x_{t-1},x_t)g_\theta^{y_t}(x_t)\,.
$$
It can also be written
$$
\phi^{y_{0:T}}_{\theta,0:T|T}(x_{0:T}) = \phi^{y_{0:T}}_{\theta,T}(x_{T}) \prod_{t=1}^Tb^{y_{0:t-1}}_{\theta,t-1|t}(x_t,x_{t-1})\,,
$$
where $\phi^{y_{0:T}}_{\theta,T}(x_{T})$ is the filtering distribution at time $T$ and for all $1\leq t \leq T$, $b^{y_{0:t-1}}_{\theta,t-1|t}(x_t,x_{t-1})$ is the backward kernel at time $t$: $b^{y_{0:t-1}}_{\theta,t-1|t}(x_t,x_{t-1})\propto \phi^{y_{0:t-1}}_{\theta,t-1}(x_{t-1})m_\theta(x_{t-1},x_t)$. The backward variational formulation is given by:
$$
q_{\varphi,0:T}^{y_{0:T}}(x_{0:T}) = q_{\varphi,T}^{y_{0:T}}(x_T)\prod_{t=1}^Tq^{y_{0:T}}_{\varphi,t-1|t}(x_t,x_{t-1})\,,
$$
so that the ELBO writes
\begin{align*}
\mathcal{L}(\theta,\varphi) &= \mathbb{E}_{q^{Y_{0:T}}_{\varphi,0:T}}\left[\log \frac{p_{\theta,0:T}(X_{0:T},Y_{0:T})}{q^{y_{0:T}}_{\varphi,0:T}(X_{0:T})}\right]\\
&= \log \int p_{\theta,0:T}(x_{0:T})p_{\theta,0:T}(Y_{0:T}|x_{0:T}) \rmd x_{0:T}\\
&\hspace{3cm}-\mathbb{E}_{q^{Y_{0:T}}_{\varphi,0:T}}\left[\log \frac{q^{Y_{0:T}}_{\varphi,0:T}(X_{0:T})\int p_{\theta,0:T}(x_{0:T})p_{\theta,0:T}(Y_{0:T}|x_{0:T})\rmd x_{0:T})}{p_{\theta,0:T}(X_{0:T},Y_{0:T})}\right]\,,\\
&= \log \int p_{\theta,0:T}(x_{0:T})p_{\theta,0:T}(Y_{0:T}|x_{0:T}) \rmd x_{0:T}- \mathrm{KL}\left(q^{Y_{0:T}}_{\varphi,0:T}\middle\| \frac{p_{\theta,0:T}(\cdot)p_{\theta,0:T}(Y_{0:T}|\cdot)}{\int p_{\theta,0:T}(x_{0:T})p_{\theta,0:T}(Y_{0:T}|x_{0:T})}\right)\,.
\end{align*}
Following \cite{tang21a}, we define the following loss function to be minimized
$$
\mathcal{L}(\theta,\varphi) = \frac{1}{n}\sum_{i=1}^nm(\theta,\varphi,Y^i_{0:T})\,,
$$
where
$$
m(\theta,\varphi,Y^i_{0:T}) = \log \frac{p_{\mathcal{D}}(Y^i_{0:T})}{\int p_{\theta,0:T}(x_{0:T})p_{\theta,0:T}(Y^i_{0:T}|x_{0:T}) \rmd x_{0:T}} + \mathrm{KL}\left(q^{Y^i_{0:T}}_{\varphi,0:T}\middle\| \frac{p_{\theta,0:T}(\cdot)p_{\theta,0:T}(Y^i_{0:T}|\cdot)}{\int p_{\theta,0:T}(x_{0:T})p_{\theta,0:T}(Y^i_{0:T}|x_{0:T})}\right)\,.
$$

\begin{hypH}
\label{assum:strong:mixing}
There exist constants $0 < \udlow < \udup < \infty$ such that for all $k \in \nset$, $\parvec\in\Theta$, $\parvar\in\parvarspace$ and $(x_k, x_{k + 1}) \in \mathbb{R}^d \times \mathbb{R}^d$, $y_{0:T}$,
$$
    \udlow \leq m_{\parvec}(x_k, x_{k + 1}) \leq \udup
$$ 
and 
$$
    \udlowvar(y_{0:T}) \leq  \vd{k\vert k+1}^{y_{0:T}}(x_{k+1}, x_{k}) \leq \udupvar(y_{0:T}). 
$$ 
\end{hypH}

\begin{hypH}
\label{assum:bound:likelihood}
For all $y$, $\mathrm{inf}_{\theta\in\Theta}\int g_\theta^y(x)\mu(\rmd x) = c_-(y)>0$ and $\mathrm{sup}_{\theta\in\Theta}\int g_\theta^y(x) \mu(\rmd x) = c_+(y)<\infty$. 

In addition, $\mathrm{sup}_{y\in\Yset} c_+(y)/c_-(y)<\infty$.
\end{hypH}

\begin{hypH}
\label{assum:lip}
There exists $M$ such that for all $\theta, \theta'$ and $x,x'$,
$$
\left| m_{\theta}(x,x') - m_{\theta'}(x,x')\right| \leq  M(x,x')\|\theta-\theta'\|_2\eqsp.
$$
For all $1\leq t \leq T$, $y_{0:T}$, there exists $K^{y_{0:T}}_{t-1|t}$ such that for all $\varphi, \varphi'$ and $x,x'$,
$$
\left| q^{y_{0:T}}_{\varphi,t-1|t}(x,x') - q^{y_{0:T}}_{\varphi',t-1|t}(x,x')\right| \leq  K^{y_{0:T}}_{t-1|t}(x',x)\|\varphi-\varphi'\|_2\eqsp.
$$
For all $0\leq t \leq T$, $y_{0:T}$, there exists $G^{y_{t}}_{t}$ such that for all $\theta, \theta'$ and $x$,
$$
\left| g_\theta^{y_{t}}(x) - g_{\theta'}^{y_{t}}(x)\right| \leq  G^{y_{t}}_{t}(x)\|\theta-\theta'\|_2\eqsp.
$$
\end{hypH}

\begin{hypH}
\label{assum:moments}
For all $1\leq t \leq T$, $y_{0:T}$, $\mu\otimes\mu(K^{y_{0:T}}_{t-1|t})<\infty$, where $K^{y_{0:T}}_{t-1|t}$ is defined in H\ref{assum:lip}. For all $0\leq t \leq T$, $y_{t}$, $\mu(G^{y_{t}}_{t})<\infty$, where $G^{y_{t}}_{t}$ is defined in H\ref{assum:lip}.
\end{hypH}


\subsection*{Checking Condition A}
In order to check Assumption A, we need to control for all $\theta$, $\theta'$, $\varphi$, $\varphi'$,
$$
\Delta(\theta, \theta', \varphi, \varphi', y_{0:T}) = \left|m(\theta,\varphi,y_{0:T})  - m(\theta',\varphi',y_{0:T}) \right|\,.
$$
Note that
\begin{align*}
\Delta(\theta, \theta', \varphi, \varphi', y_{0:T}) &= \left|m(\theta,\varphi,y_{0:T})  - m(\theta',\varphi',y_{0:T}) \right|\\
&\leq \left|\ell_T^{y_{0:T}}(\theta) - \ell_T^{y_{0:T}}(\theta')\right| + \left|\mathbb{E}_{q^{y_{0:T}}_{\varphi,0:T}}\left[\log \frac{q^{y_{0:T}}_{\varphi,0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta,0:T|T}(X_{0:T})}\right] - \mathbb{E}_{q^{y_{0:T}}_{\varphi',0:T}}\left[\log \frac{q^{y_{0:T}}_{\varphi',0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta',0:T|T}(X_{0:T})}\right]\right|\,.
\end{align*}
Write
\begin{multline*}
\left|\mathbb{E}_{q^{y_{0:T}}_{\varphi,0:T}}\left[\log \frac{q^{y_{0:T}}_{\varphi,0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta,0:T|T}(X_{0:T})}\right] - \mathbb{E}_{q^{y_{0:T}}_{\varphi',0:T}}\left[\log \frac{q^{y_{0:T}}_{\varphi',0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta',0:T|T}(X_{0:T})}\right]\right| \leq \Delta_1(\theta, \varphi, \varphi', y_{0:T}) + \Delta_2(\theta, \theta', \varphi, \varphi', y_{0:T})\,,
\end{multline*}
where
\begin{align*}
\Delta_1(\theta, \varphi, \varphi', y_{0:T})  &= \left|\mathbb{E}_{q_{\varphi,0:T}}\left[\log \frac{q^{y_{0:T}}_{\varphi,0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta,0:T|T}(X_{0:T})}\right] - \mathbb{E}_{q^{y_{0:T}}_{\varphi',0:T}}\left[\log \frac{q^{y_{0:T}}_{\varphi,0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta,0:T|T}(X_{0:T})}\right]\right|\,,\\
\Delta_2(\theta, \theta', \varphi, \varphi', y_{0:T})&= \left|\mathbb{E}_{q^{y_{0:T}}_{\varphi',0:T}}\left[\log \frac{q^{y_{0:T}}_{\varphi,0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta,0:T|T}(X_{0:T})}\right] - \mathbb{E}_{q^{y_{0:T}}_{\varphi',0:T}}\left[\log \frac{q^{y_{0:T}}_{\varphi',0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta',0:T|T}(X_{0:T})}\right]\right|
\end{align*}
Therefore, 
$$
\Delta(\theta, \theta', \varphi, \varphi', y_{0:T}) \leq \left|\ell_T^{y_{0:T}}(\theta) - \ell_T^{y_{0:T}}(\theta')\right| + \Delta_1(\theta, \varphi, \varphi', y_{0:T}) + \Delta_2(\theta, \theta', \varphi, \varphi', y_{0:T}) \,.
$$
Note that
$$
\log \frac{q^{y_{0:T}}_{\varphi,0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta,0:T|T}(X_{0:T})} = \sum_{t=1}^Th^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\eqsp,
$$
where for $1\leq t \leq T-1$, 
\begin{equation}
\label{eq:def:addfunc}
h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t) = \log q^{y_{0:T}}_{\varphi,t-1|t}(X_t,X_{t-1}) - \log b^{y_{0:t-1}}_{\theta,t-1|t}(X_t,X_{t-1})
\end{equation} 
and, by convention,  $h^{y_{0:T}}_{T,\theta,\varphi}(X_{T-1},X_T) = \log q^{y_{0:T}}_{\varphi,T}(x_T) - \log \phi^{y_{0:T}}_{\theta,T}(x_T)$. 
\begin{proposition}
\label{prop:loglikelihood:lipschitz}
For all $\theta$, $\theta'$, and all $y_{0:T}$,
$$
\left|\ell_T^{y_{0:T}}(\theta) - \ell_T^{y_{0:T}}(\theta')\right| \leq c(y_{0:T})\|\theta-\theta'\|_2\eqsp.
$$
\end{proposition}
\begin{proof}
Results already derived in the literature. Checking "good" conditions since \cite{douc2001asymptotics}.
\end{proof}

\begin{proposition}
Assume that H\ref{assum:strong:mixing}, H\ref{assum:lip} and H\ref{assum:moments} hold. Then,
$$
\Delta_1(\theta, \varphi, \varphi', y_{0:T}) \leq \udupvar(y_{0:T})\|\varphi-\varphi'\|_2\sum_{t=1}^T\left\|h^{y_{0:T}}_{t,\theta,\varphi}\right\|_\infty\sum_{s=t-1}^T\mu\otimes\mu (K_{s|s+1}) \rho(y_{0:T})^{s-t} \eqsp,
$$
where $\rho(y_{0:T}) = 1-\udlowvar(y_{0:T})/\udupvar(y_{0:T})$ and $h^{y_{0:T}}_{t,\theta,\varphi}$ is defined in \eqref{eq:def:addfunc}.
\end{proposition}
\begin{proof}
For all $\varphi,\varphi'$, $0\leq s \leq T-1$, define
\begin{multline*}
\tilde q^{y_{0:T}}_{\varphi,\varphi',t|T}(x_{0:T}) = q^{y_{0:T}}_{\varphi,T}(x_T)\prod_{s=t+1}^Tq^{y_{0:T}}_{\varphi,s-1|s}(x_s,x_{s-1})\prod_{s=1}^tq^{y_{0:T}}_{\varphi',s-1|s}(x_s,x_{s-1}) \\
- q^{y_{0:T}}_{\varphi,T}(x_T)\prod_{s=t+2}^Tq^{y_{0:T}}_{\varphi,s-1|s}(x_s,x_{s-1})\prod_{s=1}^{t+1}q^{y_{0:T}}_{\varphi',s-1|s}(x_s,x_{s-1})
\end{multline*}
and for $s=T$,
$$
\tilde q^{y_{0:T}}_{\varphi,\varphi',T|T}(x_{0:T}) = q^{y_{0:T}}_{\varphi,T}(x_T)\prod_{s=1}^Tq^{y_{0:T}}_{\varphi',s-1|s}(x_s,x_{s-1}) 
- q^{y_{0:T}}_{\varphi',T}(x_T)\prod_{s=1}^Tq^{y_{0:T}}_{\varphi',s-1|s}(x_s,x_{s-1})\eqsp.
$$
Therefore,
$$
\mathbb{E}_{q^{y_{0:T}}_{\varphi,0:T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right] - \mathbb{E}_{q^{y_{0:T}}_{\varphi',0:T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right] = \sum_{s=0}^T \mathbb{E}_{\tilde q^{y_{0:T}}_{\varphi,\varphi',s|T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right] \eqsp.
$$
Note first that if $t> s+1$, then $\mathbb{E}_{\tilde q^{y_{0:T}}_{\varphi,\varphi',s|T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right] = 0$ so that
$$
\mathbb{E}_{q^{y_{0:T}}_{\varphi,0:T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right] - \mathbb{E}_{q^{y_{0:T}}_{\varphi',0:T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right] = \sum_{s=t-1}^T \mathbb{E}_{\tilde q^{y_{0:T}}_{\varphi,\varphi',s|T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right] \eqsp.
$$
For all $t\leq s+1$, write for all measurable set $A$
\begin{align*}
\mu^{y_{0:T}}_{\varphi,s}(A) &= \int \mathds{1}_A(x_s) q^{y_{0:T}}_{\varphi,T}(\rmd x_T)\prod_{u=s+1}^Tq^{y_{0:T}}_{\varphi,u-1|u}(x_u,\rmd x_{u-1})\eqsp,\\
\tilde\mu^{y_{0:T}}_{\varphi,\varphi',s}(A) &= \int \mathds{1}_A(x_s) q^{y_{0:T}}_{\varphi,T}(\rmd x_T)\prod_{u=s+2}^Tq^{y_{0:T}}_{\varphi,u-1|u}(x_u,\rmd x_{u-1})q^{y_{0:T}}_{\varphi',s|s+1}(x_{s+1},\rmd x_{s})\eqsp.
\end{align*}
Therefore,
$$
\mathbb{E}_{\tilde q^{y_{0:T}}_{\varphi,\varphi',s|T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right] = \left(\mu^{y_{0:T}}_{\varphi,s} - \tilde\mu^{y_{0:T}}_{\varphi,\varphi',s}\right)\left\{\prod_{u=t+1}^{s}q^{y_{0:T}}_{\varphi',u-1|u}\right\}q^{y_{0:T}}_{\varphi',t-1|t}h^{y_{0:T}}_{t,\theta,\varphi}
$$
and, using A\ref{assum:strong:mixing},
$$
\mathbb{E}_{\tilde q^{y_{0:T}}_{\varphi,\varphi',s|T}}\left[h^{y_{0:T}}_{t,\theta,\varphi}(X_{t-1},X_t)\right]  \leq \frac{1}{2}\|\mu^{y_{0:T}}_{\varphi,s}-\tilde\mu^{y_{0:T}}_{\varphi,\varphi',s}\|_{\mathrm{tv}}\rho(y_{0:T})^{s-t}\mathrm{osc}\left(q^{y_{0:T}}_{\varphi',t-1|t}h^{y_{0:T}}_{t,\theta,\varphi}\right)\eqsp.
$$
Noting that by H\ref{assum:lip},
$$
\|\mu_{\varphi,s}-\tilde\mu_{\varphi,\varphi',s}\|_{\mathrm{tv}} \leq q^{y_{0:T}}_{\varphi,T}\prod_{s=t+1}^Tq_{\varphi,s-1|s}K_{s|s+1}\|\varphi-\varphi'\|_2\leq \udupvar(y_{0:T})\mu\otimes\mu (K_{s|s+1})\|\varphi-\varphi'\|_2\eqsp,
$$
concludes the proof with Lemma~\ref{lem:bound:addfunc}.
\end{proof}


\begin{proposition}
Assume that H\ref{assum:strong:mixing}, H\ref{assum:bound:likelihood} and H\ref{assum:lip} hold. Then,
\begin{multline*}
\Delta_2(\theta, \theta', \varphi, \varphi', y_{0:T}) \leq  \sigma_-\|\varphi-\varphi'\|_2\sum_{t=1}^Tq_{\varphi',0:T}K_{t-1|t}\\
+\|\theta-\theta'\|_2\sum_{t=1}^T\frac{\sigma_+c_+(y_t)}{\sigma^2_-c_-(y_t)}\left(R_{1,t|T,\varphi'}(y_{0:t-1})  + R_{2,t,\theta'}(y_{0:t-1}) \right)\eqsp,
\end{multline*}
where 
\begin{align*}
R_{1,t|T,\varphi'}(y_{0:t-1}) &= \int q_{\varphi',0:T}(\rmd x_{0:T})M(x_{t-1},x_t) + \frac{\sigma_+}{\sigma_-}q_{\varphi',0:T}L_{t-1}(\cdot,y_{0:t-1})\eqsp,\\
R_{2,t,\theta'}(y_{0:t-1}) &= \int \phi_{\theta',t-1}^{y_{0:t-1}}(x_{t-1})M(x_{t-1},X_t)\mu(\rmd x_{t-1}) + \int L_{t-1}(x_{t-1},y_{0:t-1})m_{\theta'}(x_{t-1},X_t)\mu(\rmd x_{t-1})\eqsp.
\end{align*}
\end{proposition}
\begin{proof}
By definition, 
\begin{align*}
\Delta_2(\theta, \theta', \varphi, \varphi', y_{0:T}) &= \left|\mathbb{E}_{q_{\varphi',0:T}}\left[\log \frac{q_{\varphi,0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta,0:T|T}(X_{0:T})}\right] - \mathbb{E}_{q_{\varphi',0:T}}\left[\log \frac{q_{\varphi',0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta',0:T|T}(X_{0:T})}\right]\right|\,,\\
&\leq \mathbb{E}_{q_{\varphi',0:T}}\left[\left|\log \frac{q_{\varphi,0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta,0:T|T}(X_{0:T})} - \log \frac{q_{\varphi',0:T}(X_{0:T})}{\phi^{y_{0:T}}_{\theta',0:T|T}(X_{0:T})}\right|\right]\,,\\
&\leq \sum_{t=1}^T\mathbb{E}_{q_{\varphi',0:T}}\left[\left|h_{t,\theta,\varphi}(X_{t-1},X_t)-h_{t,\theta',\varphi'}(X_{t-1},X_t)\right|\right]\,,
\end{align*}
where $h_{t,\theta,\varphi}$, $1\leq t\leq T$,  are defined in \eqref{eq:def:addfunc}. For $t>1$,
\begin{multline*}
\left|h_{t,\theta,\varphi}(X_{t-1},X_t)-h_{t,\theta',\varphi'}(X_{t-1},X_t)\right| \leq \left|\log q_{\varphi,t-1|t}(X_t,X_{t-1}) - \log q_{\varphi',t-1|t}(X_t,X_{t-1})\right|\\
+ \left|\log b^{y_{0:t-1}}_{\theta,t-1|t}(X_t,X_{t-1})- \log b^{y_{0:t-1}}_{\theta',t-1|t}(X_t,X_{t-1})\right|\eqsp.
\end{multline*}
By H\ref{assum:lip},
\begin{multline*}
\left|h_{t,\theta,\varphi}(X_{t-1},X_t)-h_{t,\theta',\varphi'}(X_{t-1},X_t)\right| \leq \sigma_- K_{t-1|t}(X_{t-1},X_t)\|\varphi-\varphi'\|_2 \\
+ \left|\log b^{y_{0:t-1}}_{\theta,t-1|t}(X_t,X_{t-1})- \log b^{y_{0:t-1}}_{\theta',t-1|t}(X_t,X_{t-1})\right|\eqsp.
\end{multline*}
Note that, by Lemma~\ref{lem:bound:filter},
$$
b^{y_{0:t-1}}_{\theta,t-1|t}(X_t,X_{t-1}) = \frac{\phi_{\theta,t-1}^{y_{0:t-1}}(X_{t-1})m_\theta(X_{t-1},X_t)}{\int \phi_{\theta,t-1}^{y_{0:t-1}}(x_{t-1})m_\theta(x_{t-1},X_t)\mu(\rmd x_{t-1})}\geq \frac{\sigma^2_-c_-(y_t)}{\sigma_+c_+(y_t)}\eqsp,
$$
so that
\begin{multline*}
\left|h_{t,\theta,\varphi}(X_{t-1},X_t)-h_{t,\theta',\varphi'}(X_{t-1},X_t)\right| \leq \sigma_- K_{t-1|t}(X_{t-1},X_t)\|\varphi-\varphi'\|_2 \\
+ \frac{\sigma_+c_+(y_t)}{\sigma^2_-c_-(y_t)}\left|b^{y_{0:t-1}}_{\theta,t-1|t}(X_t,X_{t-1})- b^{y_{0:t-1}}_{\theta',t-1|t}(X_t,X_{t-1})\right|\eqsp.
\end{multline*}
In addition,
\begin{align*}
\left|\log b^{y_{0:t-1}}_{\theta,t-1|t}(X_t,X_{t-1})- \log b^{y_{0:t-1}}_{\theta',t-1|t}(X_t,X_{t-1})\right| &= \frac{\phi_{\theta,t-1}^{y_{0:t-1}}(X_{t-1})m_\theta(X_{t-1},X_t) - \phi_{\theta',t-1}^{y_{0:t-1}}(X_{t-1})m_{\theta'}(X_{t-1},X_t)}{\int \phi_{\theta,t-1}^{y_{0:t-1}}(x_{t-1})m_\theta(x_{t-1},X_t)\mu(\rmd x_{t-1})}\\
&+ \phi_{\theta',t-1}^{y_{0:t-1}}(X_{t-1})m_{\theta'}(X_{t-1},X_t)\left(\frac{1}{\int \phi_{\theta,t-1}^{y_{0:t-1}}(x_{t-1})m_\theta(x_{t-1},X_t)\mu(\rmd x_{t-1})} - \frac{1}{\int \phi_{\theta',t-1}^{y_{0:t-1}}(x_{t-1})m_{\theta'}(x_{t-1},X_t)\mu(\rmd x_{t-1})}\right)\eqsp.
\end{align*}
This yields
\begin{multline*}
\left|\log b^{y_{0:t-1}}_{\theta,t-1|t}(X_t,X_{t-1})- \log b^{y_{0:t-1}}_{\theta',t-1|t}(X_t,X_{t-1})\right| \leq \left(\frac{\sigma_+c_+(y_t)}{\sigma_-c_-(y_t)}M(X_{t-1},X_t) + \frac{\sigma_+}{\sigma_-}L_{t-1}(x_{t-1},y_{0:t-1})\right)\|\theta-\theta'\|_2\\
+ \frac{\sigma^2_+c_+(y_t)}{\sigma^2_-c_-(y_t)}\left(\int \phi_{\theta',t-1}^{y_{0:t-1}}(x_{t-1})M(x_{t-1},X_t)\mu(\rmd x_{t-1}) + \int L_{t-1}(x_{t-1},y_{0:t-1})m_{\theta'}(x_{t-1},X_t)\mu(\rmd x_{t-1})\right)\|\theta-\theta'\|_2
\end{multline*}
\end{proof}
\subsection*{Checking Assumption A}
%Steps of the proof.
%\begin{itemize}
%\item The first term can be written
%$$
%\left|\ell_T^{y_{0:T}}(\theta) - \ell_T^{y_{0:T}}(\theta')\right| \leq \sum_{t=0}^T\left| \log p_{\theta}(y_{t}|y_{1:t-1})  - \log p_{\theta'}(y_{t}|y_{1:t-1})\right|\,,
%$$
%where by convention $p_{\theta}(y_{0}|y_{-1}) = p_{\theta}(y_{0})$ and $p_{\theta'}(y_{0}|y_{-1}) = p_{\theta'}(y_{0})$. This term can be upper bounded by $\|\theta-\theta'\|$ regularity assumptions on the HMMs.
%\item $\Delta_1(\theta, \theta', \varphi, \varphi', y_{0:T})$ can be written
%$$
%\Delta_1(\theta, \theta', \varphi, \varphi', y_{0:T}) =  \left|\mathbb{E}_{q_{\varphi,0:T}}\left[\sum_{t=0}^Th_{\theta,\varphi,t}(X_{t-1},X_t)\right] - \mathbb{E}_{q_{\varphi',0:T}}\left[\sum_{t=0}^Th_{\theta,\varphi,t}(X_{t-1},X_t)\right]\right|\,,
%$$
%which can be controlled using the upper bound for smoothing expectations of additive functionals.
%\item Obtaining 
%$$
%\Delta_2(\theta, \theta', \varphi, \varphi', y_{0:T}) \leq c_2(y_{0:T}) \|(\theta,\varphi)-(\theta',\varphi')\|_2
%$$
%requires regularity assumptions on $\varphi\mapsto q_{\varphi,0:T}$ and $\theta\mapsto \phi^{y_{0:T}}_{\theta,0:T|T}$.
%\end{itemize}

\section{Technical results}
\begin{lemma}
\label{lem:bound:filter}
Assume that H\ref{assum:strong:mixing} and H\ref{assum:bound:likelihood} hold. For all $\theta\in\Theta$,  all $t\geq 0$, all $y_{0:t}$,
$$
\sigma_- c_-(y_t)/c_+(y_t)\leq \phi^{y_{0:t}}_{\theta,t}(x_{t})\leq \sigma_+ c_+(y_t)/c_-(y_t)\,.
$$
\end{lemma}
\begin{proof}
At time 0, we have $\phi^{y_{0}}_{\theta,0}(x_{0}) \propto \chi(x_0)g^{y_0}_\theta(x_0)$, so that $\sigma_- c_-(y_0)/c_+(y_0)\leq \phi^{y_{0}}_{\theta,0}(x_{0})\leq \sigma_+ c_+(y_0)/c_-(y_0)$. Similarly, 
$$
\phi^{y_{0:t}}_{\theta,t}(x_{t}) \propto g^{y_t}_\theta(x_t)\int \phi^{y_{0:t-1}}_{\theta,t-1}(x_{t-1})m_\theta(x_{t-1},x_t)\rmd x_{t-1}\,,
$$
so that $\sigma_- c_-(y_t)/c_+(y_t)\leq \phi^{y_{0:t}}_{\theta,t}(x_{t})\leq \sigma_+ c_+(y_t)/c_-(y_t)$.
\end{proof}

\begin{lemma}
\label{lem:bound:addfunc}
Assume that H\ref{assum:strong:mixing} and H\ref{assum:bound:likelihood} hold. For all $\theta$, $\varphi$  all $1\leq t\leq T$, all $y_{0:T}$, $x_{t-1}$, $x_t$,
$$
\frac{\sigma^2_-c_-(y_{t-1})}{\sigma_+c_+(y_{t-1})}\leq b^{y_{0:t-1}}_{\theta,t-1|t}(x_t,x_{t-1}) \leq \frac{\sigma^2_-+c_+(y_{t-1})}{\sigma_-c_-(y_{t-1})}
$$
and for $1\leq t \leq T-1$,
$$
\|h^{y_{0:T}}_{t,\theta,\varphi}\|_\infty \leq \frac{\sigma_+c_+(y_{t-1})}{\sigma_-c_-(y_{t-1})}\frac{\sigma^2_+c_+(y_{t-1})+\sigma_-c_-(y_{t-1})\udupvar(y_{0:T})}{ \sigma^2_-c_-(y_{t-1}) \wedge \sigma_+c_+(y_{t-1})\udlowvar(y_{0:T})}\eqsp,
$$
and 
$$
\|h^{y_{0:T}}_{T,\theta,\varphi}\|_\infty \leq \frac{c_+(y_T)}{c_-(y_T)}\frac{c_-(y_T)\udupvar(y_{0:T}) +  \udup c_+(y_T)}{c_+(y_T)\udlowvar(y_{0:T})\wedge \udlow c_-(y_T)}\eqsp,
$$
where $h_{t,\theta,\varphi}$, $1\leq t\leq T$,  are defined in \eqref{eq:def:addfunc}.
\end{lemma}
\begin{proof}
Note that by \eqref{eq:def:addfunc}, for $1\leq t \leq T-1$,  $h^{y_{0:T}}_{t,\theta,\varphi}(x_{t-1},x_t) = \log q^{y_{0:T}}_{\varphi,t-1|t}(x_t,x_{t-1}) - \log b^{y_{0:t-1}}_{\theta,t-1|t}(x_t,x_{t-1})$ and, by convention,  $h^{y_{0:T}}_{T,\theta,\varphi}(x_{T-1},x_T) = \log q^{y_{0:T}}_{\varphi,T}(x_T) - \log \phi^{y_{0:T}}_{\theta,T}(x_T)$. Note that, by Lemma~\ref{lem:bound:filter}, for $1\leq t\leq T-1$,
$$
\frac{\sigma^2_-c_-(y_{t-1})}{\sigma_+c_+(y_{t-1})}\leq b^{y_{0:t-1}}_{\theta,t-1|t}(x_t,x_{t-1}) = \frac{\phi_{\theta,t-1}^{y_{0:t-1}}(x_{t-1})m_\theta(x_{t-1},x_t)}{\int \phi_{\theta,t-1}^{y_{0:t-1}}(x_{t-1})m_\theta(x_{t-1},x_t)\mu(\rmd x_{t-1})}\leq \frac{\sigma^2_+c_+(y_{t-1})}{\sigma_-c_-(y_{t-1})}\eqsp,
$$
so that
$$
\|h^{y_{0:T}}_{t,\theta,\varphi}\|_\infty \leq \frac{\frac{\sigma^2_+c_+(y_{t-1})}{\sigma_-c_-(y_{t-1})}+\udupvar(y_{0:T})}{ \frac{\sigma^2_-c_-(y_{t-1})}{\sigma_+c_+(y_{t-1})} \wedge \udlowvar(y_{0:T})}\eqsp,
$$
which concludes the proof. In addition, by Lemma~\ref{lem:bound:filter},
$$
\|h^{y_{0:T}}_{t,\theta,\varphi}\|_\infty \leq \frac{\udupvar(y_{0:T}) +  \udup c_+(y_T)/c_-(y_T)}{\udlowvar(y_{0:T})\wedge \udlow c_-(y_T)/c_+(y_T)}\eqsp.
$$

\end{proof}

\begin{lemma}
Assume that H\ref{assum:strong:mixing}, H\ref{assum:bound:likelihood} and H\ref{assum:lip} hold. Then, for all $\theta$, $\theta'$, $t\geq 1$
$$
\left|\phi_{\theta,t}^{y_{0:t}}(x_{t}) - \phi_{\theta',t}^{y_{0:t}}(x_{t})\right| \leq  L_t(x_t,y_{0:t})\|\theta-\theta'\|_2\eqsp,
$$
where for $t\geq 1$,
$$
L_t(x_t,y_{0:t}) = \eqsp,
$$
and
$$
L_0(x_0,y_{0}) = \frac{\udup}{\udlow c_-(y_0)}G^{y_{0}}_{0}(x_0)+ \frac{\udup\mu\left(G^{y_{0}}_{0}\right)}{\udlow^2c^2_-(y_0)}\eqsp.
$$
\end{lemma}
\begin{proof}
At time $t=0$, note that $\phi_{\theta,0}^{y_{0}}(x_{0})\propto \chi(x_0)g_\theta^{y_0}(x_0)$. Therefore,
\begin{align*}
\left|\phi_{\theta,0}^{y_{0}}(x_{0}) - \phi_{\theta',0}^{y_{0}}(x_{0})\right|&=\left|\frac{\chi(x_0)g_\theta^{y_0}(x_0)}{\int \chi(x_0)g_\theta^{y_0}(x_0)\mu(\rmd x_0)} - \frac{\chi(x_0)g_{\theta'}^{y_0}(x_0)}{\int \chi(x_0)g_{\theta'}^{y_0}(x_0)\mu(\rmd x_0)}\right|\eqsp,\\
&=\left|\frac{\chi(x_0)\left(g_\theta^{y_0}(x_0)-g_{\theta'}^{y_0}(x_0)\right)}{\int \chi(x_0)g_\theta^{y_0}(x_0)\mu(\rmd x_0)} + \chi(x_0)g_{\theta'}^{y_0}(x_0)\left(\frac{1}{\int \chi(x_0)g_{\theta}^{y_0}(x_0)\mu(\rmd x_0)}-\frac{1}{\int \chi(x_0)g_{\theta'}^{y_0}(x_0)\mu(\rmd x_0)}\right)\right|\eqsp,\\
&\leq \left(\frac{\udup}{\udlow c_-(y_0)}G^{y_{0}}_{0}(x_0)+ \frac{\udup\mu\left(G^{y_{0}}_{0}\right)}{\udlow^2c^2_-(y_0)}\right)\|\theta-\theta'\|_2\eqsp. 
\end{align*}
For $t>0$, note that $\phi_{\theta,t}^{y_{0:t}}(x_{t}) =  g_\theta^{y_t}(x_t)\int \phi_{\theta,t-1}^{y_{0:t-1}}(x_{t-1})m_\theta(x_{t-1},x_t)\mu(\rmd x_{t-1})/c_{\theta,t}(y_{0:t})$ where $c_{\theta,t}(y_{0:t}) = \int g_\theta^{y_t}(x_t) \phi_{\theta,t-1}^{y_{0:t-1}}(x_{t-1})m_\theta(x_{t-1},x_t)\mu(\rmd x_{t-1})\mu(\rmd x_{t})$. Therefore, using that $c_{\theta,t}(y_{0:t})\wedge c_{\theta',t}(y_{0:t})\geq \udlow c_-(y_t)$,
\begin{align*}
\left|\phi_{\theta,t}^{y_{0:t}}(x_{t}) - \phi_{\theta',t}^{y_{0:t}}(x_{t})\right|&=\left|\frac{g_\theta^{y_t}(x_t)\phi_{\theta,t-1}^{y_{0:t-1}}(m_\theta(\cdot,x_t))}{c_{\theta,t}(y_{0:t})} - \frac{g_{\theta'}^{y_t}(x_t)\phi_{\theta',t-1}^{y_{0:t-1}}(m_{\theta'}(\cdot,x_t))}{c_{\theta',t}(y_{0:t})}\right|\eqsp,\\
&=\left|\frac{g_\theta^{y_t}(x_t)\phi_{\theta,t-1}^{y_{0:t-1}}(m_\theta(\cdot,x_t))-g_{\theta'}^{y_t}(x_t)\phi_{\theta',t-1}^{y_{0:t-1}}(m_{\theta'}(\cdot,x_t))}{c_{\theta,t}(y_{0:t})}+g_{\theta'}^{y_t}(x_t)\phi_{\theta',t-1}^{y_{0:t-1}}(m_{\theta'}(\cdot,x_t))\frac{c_{\theta',t}(y_{0:t})-c_{\theta,t}(y_{0:t})}{c_{\theta,t}(y_{0:t})c_{\theta',t}(y_{0:t})}\right|\eqsp,\\
&\leq \left(\frac{\udup G^{y_t}(x_t) + g^{y_t}_{\theta'}(x_t)}{\udlow c_-(y_t)}+ \frac{}{\udlow^2c^2_-(y_t)}\right)\|\theta-\theta'\|_2\eqsp. 
\end{align*}
\end{proof}

%\clearpage
%\newpage
%
%\appendix
%
%\textcolor{red}{Other results for other projects...}
%
%\section{Theoretical perspectives}
%
%Observations $(Y_{t})_{1\leq t \leq T}$, latent variables $(X_{t})_{1\leq t \leq T}$.\\
%True (unknown) density distribution $p^{\star}$.\\
%Decoding (= model) $p_{\theta}$: joint density of $(X_{t}, Y_{t})_{1\leq t \leq T}$. Write $\theta$ even if non parametric.\\
%Encoding $q_{\varphi}$: joint density of $(X_{t})_{1\leq t \leq T}$ given $(Y_{t})_{1\leq t \leq T}$, that is a joint density which is random, and $\sigma(Y_{1},\ldots,Y_{T})$-measurable. May also be non parametric.  The estimators $\widehat{\theta}$ and $\widehat{\phi}$ maximize the ELBO:
%$$
%{\cal L}(\theta,\phi; T)= \E_{q_{\varphi}} \left[ \log \left( \frac{p_{\theta}(X_{1},\ldots,X_{T},Y_{1},\ldots,Y_{T})}{q_{\varphi}(X_{1},\ldots,X_{T})}\right)\middle\vert Y_{1:T}\right].
%$$
%
%\subsection{Independent variables}
%
%We consider that the true distribution, decoder and encoder distributions are defined by:
%\begin{align*}
%p^{\star}(x_{1},\ldots,x_{T},y_{1},\ldots,y_{T})&=\prod_{t=1}^{T}p^{\star}(x_{t},y_{t})\,,\\
%p_{\theta}(x_{1},\ldots,x_{T},y_{1},\ldots,y_{T})&=\prod_{t=1}^{T}p_{\theta}(x_{t},y_{t})\,,\\
%q_{\varphi}(x_{1},\ldots,x_{T})&=\prod_{t=1}^{T}q_{\varphi,t}(x_{t})\,.
%\end{align*}
%Therefore,
%$$
%\frac{1}{T}{\cal L}(\theta,\phi; T) = \frac{1}{T}\sum_{t=1}^T\log p_\theta(Y_t) + \frac{1}{T}\sum_{t=1}^T\E_{q_{\varphi,t}}\left[\log \frac{p_\theta(X_t|Y_t)}{q_{\varphi,t}(X_t)}\right]\,.
%$$
%When $q_{\varphi,t}(x_{t})=q_{\varphi}(x_{t}|y_t)$ does not depend on $t$, then ${\cal L}(\theta,\phi; T)/T$ has a a.s. limit:
%$$
%\lim_{T\mapsto \infty}\frac{1}{T}{\cal L}(\theta,\phi; T) = M_{\infty}(\theta,\phi)=\int p^{\star}(y)\log p_{\theta}(y) dy - \int \log \left(\frac{q_{\varphi}(x\vert y)}{p_{\theta}(x \vert y) } \right)q_{\varphi}(x\vert y)\,.
%p^{\star}(y)dxdy
%$$
%The maximizers of this limit are investigated in \cite{koehler2021variational} in scenarii used in VAE.  The analysis of $(\widehat{\theta},\widehat{\phi})$ as $M-estimators$ with oracle inequalities and applications is in \cite{tang21a}.
%If we assume that the $q_{\varphi,t}$ indeed depend on $t$, then if we write for each $\theta$,
%$$
%\widehat{q}_{\theta,t}=q_{\widehat{\varphi}_{t}(\theta),t}= \underset{{q \text{ of form }q_{\varphi},t}}{\mathrm{argmin}} \int  \left[\log \left(\frac{q(x\vert Y_{t})}{p_{\theta}(x \vert Y_{t}) } \right)\right]q(x\vert Y_{t})dx,
%$$
%then $\widehat{\theta}$ maximizes
%$$
%\ell_{T}(\theta)-\sum_{t=1}^{T} D\left(\widehat{q}_{t,\theta} \vert p_{\theta}(\cdot \vert Y_{t})\right),
%$$
%where $\ell_{T}$ is the log-likelihood, thus something like a penalized likelihood. All of this is  interesting only if such VAE with so many parameters for the encoding   is used for computational convenience or so. If this is the case, then write a theory to investigate questions such as:
%\begin{itemize}
%\item If the encoder is a good approximating family then the penalization is small; can it be build so that the penalty is $o(T)$ ? 
%\item
%And then possible to analyse that for large $T$ (or asymptotically) if $p^{\star}$ is in the decoding class,  for large $t$ is close to $p_{\widehat{\theta}}(\cdot \vert Y)$ for $\widehat{\theta}$ having good asymptotic properties ?
%\end{itemize}
%
% 
%\subsection{State space decoding}
%We consider that 
%
%$$p_{\theta}(x_{1},\ldots,x_{T},y_{1},\ldots,y_{T})=p_{\theta}(x_{1})g_{\theta}(y_{1}\vert x_{1})\prod_{t=2}^{T}p_{\theta}(x_{t-1},x_{t})g_{\theta}(y_{t} \vert x_{t}).
%$$ 
%
%
%\subsubsection{Mean-field encoding}
%The case where
%$$q_{\varphi}(x_{1},\ldots,x_{T})=\prod_{t=1}^{T}q_{\varphi}(x_{t}).$$
%Then ${\cal L}(\theta,\phi; T)/T$ has a limit (as soon as under $p^{\star}$ the $(Y_{t})_{t\geq 1}$ satisfy some dependence properties allowing laws of large numbers):
%$$
%\lim_{T\mapsto \infty}\frac{1}{T}{\cal L}(\theta,\phi; T) = M_{\infty}(\theta,\phi)=\int p^{\star}(y) q_{\varphi}(x_{1}\vert y)q_{\varphi}(x_{2}\vert y)
% \left[\log \left(\frac{p_{\theta}(x_{1},x_{2} ) g_{\theta}(x_{2}\vert y)}{q_{\varphi}(x_{2}\vert y)} \right)\right]
%dx_{1}dx_{2}dy
%$$
%What can be said ?
%\begin{itemize}
%\item
%Write the $M$-estimator  oracle inequality theory. Or at least the asymptotic theory.
%\item
%Understand the bias (that is: the maximizers of $M_{\infty}$) in interesting examples.
%\end{itemize}
%
%\subsubsection{HMM encoding/ Forward / Backward encoding}
%
%\begin{itemize}
%\item {\bf Parameterization as in Chagneux et al. } Assume that the variational family is parameterized by $\{\phi^T_{\varphi,t},q_{\varphi,t-1|t}\}_{0\leq t\leq T}$ where for all $0\leq t\leq T$, $\phi_{\varphi,t}$ is a probability density on $\rset^d$, and $q_{\varphi,t-1|t}$ a transition kernel on $\rset^d\times \rset^d$. Then, write
%$$
%q_{\varphi,0:T}(x_{0:T}) = \phi^T_{\varphi,T}(x_T)\prod_{t=1}^Tq_{\varphi,t-1|t}(x_t,x_{t-1})\,.
%$$
%In this decomposition, $q_{\varphi,t-1|t}$ aims at approximating the true backward kernel of the hidden chain. In this setting, we can write
%$$
%q_{\varphi,0:T}(x_{0:T}) = \frac{\phi^T_{\varphi,T}(x_T)}{\phi^{T-1}_{\varphi,T-1}(x_{T-1})}q_{\varphi,T-1|T}(x_T,x_{T-1})q_{\varphi,0:T-1}(x_{0:T-1})
%$$
%and the ELBO writes
%\begin{align*}
%\mathcal{L}_T(\theta,\varphi) &= \mathbb{E}_{q_{\varphi,0:T}}\left[F_{\theta,\varphi,T}(X_{0:T},Y_{0:T})\right] = \mathbb{E}_{q_{\varphi,0:T}}\left[\log \frac{p_{\theta,0:T}(X_{0:T},Y_{0:T})}{q_{\varphi,0:T}(X_{0:T})}\right]\\
%&= \mathbb{E}_{q_{\varphi,0:T}}\left[\log  \frac{p_{\theta,T}(X_{T-1},X_T)g_{\theta,T}(X_T)\phi^{T-1}_{\varphi,T-1}(X_{T-1})}{q_{\varphi,T-1|T}(X_T,X_{T-1})\phi^T_{\varphi,T}(X_T)}\right] + \mathbb{E}_{q_{\varphi,0:T}}\left[F_{\theta,\varphi,T-1}(X_{0:T-1},Y_{0:T-1})\right]\,.
%\end{align*}
%Let 
%$$
%\nu_{\varphi,T-1:T}(x_{T-1},x_T) = \phi^T_{\varphi,T}(x_T)q_{\varphi,T-1|T}(x_T,x_{T-1})$$ and 
%\begin{align*}
%\mu_{\theta,\varphi,T-1:T}(x_{T-1},x_T) &\propto p_{\theta,T}(X_{T-1},X_T)g_{\theta,T}(X_T)\phi^{T-1}_{\varphi,T-1}(X_{T-1}) \\
%&= c_{\theta,\varphi,T}p_{\theta,T}(X_{T-1},X_T)g_{\theta,T}(X_T)\phi^{T-1}_{\varphi,T-1}(X_{T-1})\,.
%\end{align*}
%Then,
%\begin{align*}
%\mathcal{L}_T(\theta,\varphi) &= - \log c_{\theta,\varphi,T}  + \mathbb{E}_{\nu_{\varphi,T-1:T}}\left[\log \frac{\mu_{\theta,\varphi,T-1:T}}{\nu_{\varphi,T-1:T}}\right]  + \mathbb{E}_{q_{\varphi,0:T}}\left[F_{\theta,\varphi,T-1}(X_{0:T-1},Y_{0:T-1})\right]\,,\\
%&= - \log c_{\theta,\varphi,T}  -\mathrm{KL}(\nu_{\varphi,T-1:T}\|\nu_{\varphi,T-1:T})  + \mathbb{E}_{q_{\varphi,0:T}}\left[F_{\theta,\varphi,T-1}(X_{0:T-1},Y_{0:T-1})\right]\,.
%\end{align*}
%\item {\bf Parameterization using forward kernels and filtering distributions. } Assume that the variational family is parameterized by $\{\phi_{\varphi,t},m_{\varphi,t|t-1}\}_{0\leq t\leq T}$ where for all $0\leq t\leq T$, $\phi_{\varphi,t}$ is a probability density on $\rset^d$, and $m_{\varphi,t|t-1}$ a transition kernel on $\rset^d\times \rset^d$. Then, write
%$$
%q_{\varphi,0:T}(x_{0:T}) = \phi_{\varphi,T}(x_T)\prod_{t=1}^Tq_{\varphi,t-1|t}(x_t,x_{t-1})\,,
%$$
%where $q_{\varphi,t-1|t}(x_t,x_{t-1}) \propto \phi_{\varphi,t-1}(x_{t-1})m_{\varphi,t|t-1}(x_{t-1},x_t) = c_{\varphi,t}(x_t)\phi_{\varphi,t-1}(x_{t-1})m_{\varphi,t|t-1}(x_{t-1},x_t)$. In this decomposition, $q_{\varphi,t-1|t}$ aims at approximating the true prior kernel of the hidden chain and $\phi_{\varphi,t}$ the true filtering distribution at time $t$. In this setting, the ELBO writes
%\begin{align*}
%\mathcal{L}(\theta,\varphi) &= \mathbb{E}_{q_{\varphi,0:T}}\left[\log \frac{p_{\theta,0:T}(X_{0:T},Y_{0:T})}{q_{\varphi,0:T}(X_{0:T})}\right]\\
%&= -\sum_{t=1}^T\mathbb{E}_{q_{\varphi,0:T}}\left[\log c_{\varphi,t}(x_t)\right] + \sum_{t=1}^T\mathbb{E}_{q_{\varphi,0:T}}\left[\log \frac{p_\theta(x_{t-1},x_t)g_\theta(y_t|x_t)}{ \phi_{\varphi,t-1}(X_{t-1})m_{\varphi,t|t-1}(X_{t-1},X_t) }\right]\,,
%\end{align*}
%with $p_\theta(x_{-1},x_0) = \nu_\theta(x_0)$.
%\end{itemize}
%
%\clearpage
%\newpage
%
%\subsection*{Limiting ELBO}
%
%For any probability density distribution $\chi$, $s>m$, $\bfy\in\Yset^{\Zset}$, $\theta$ write
%$$
%\phi^{\bfy_{0:s}}_{\theta,s|m,\chi}(x_{s}) \propto \int \chi(\rmd x_m)g_\theta^{\bfy_m}(x_m)\prod_{u=m+1}^s m_\theta(x_{u-1},x_u)g_\theta^{\bfy_u}(x_u)\rmd x_{m:s-1}
%$$
%the filtering distribution at time $s$ for the model started at time $m$ with distribution $\chi$. We use the convention $\phi^{\bfy_{0:s}}_{\theta,s} = \phi^{\bfy_{0:s}}_{\theta,s|0,\eta}$.
%For all $t\geq 1$, consider the joint variational distribution
%$$
%q^{\bfy}_{\varphi,0:t}(x_{0:t}) = \phi^{\bfy}_{\varphi,t}(x_t)\prod_{s=1}^tq^{\bfy}_{\varphi,s-1|s}(x_s,x_{s-1})\,,
%$$
%and, using the backward decomposition of the joint smoothing distribution,
%$$
%\phi^{\bfy_{0:t}}_{\theta,0:t}(x_{0:t}) = \phi^{\bfy_{0:t}}_{\theta,t}(x_t)\prod_{s=1}^tb^{\bfy_{0:s-1}}_{\theta,s-1|s}(x_s,x_{s-1})\,,
%$$
%where $b^{\bfy_{0:s-1}}_{\theta,s-1|s}$ is the backward kernel at time $s$:
%\begin{equation}
%\label{eq:backwardk}
%b^{\bfy_{0:s-1}}_{\theta,s-1|s}(x_s,x_{s-1}) \propto \phi^{\bfy_{0:s-1}}_{\theta,s-1}(x_{s-1})m_\theta(x_{s-1},x_s)\,.
%\end{equation}
%The ELBO writes, for all $\bfy\in\Yset^{\Zset}$, $\theta\in\Theta$, $\varphi\in\Phi$,
%$$
%\frac{1}{t}\mathcal{L}^{\bfy_{0:t}}(\theta,\varphi)= \frac{1}{t}\ell^{\bfy_{0:t}}(\theta) +  \frac{1}{t}\mathbb{E}_{\phi^{\bfy_{0:t}}_{\varphi,t}}\left[\log \frac{\phi^{\bfy_{0:t}}_{\theta,t}(X_{t})}{q^{\bfy}_{\varphi,t}(X_{t})}\right] + \frac{1}{t}\sum_{s=1}^t\mathbb{E}_{q^{\bfy}_{\varphi,0:t}}\left[\log \frac{b^{\bfy_{0:s-1}}_{\theta,s-1|s}(X_{s-1},X_s)}{q^{\bfy}_{\varphi,s-1|s}(X_{s-1},X_s)}\right]\,,
%$$
%where $\ell^{\bfy_{0:t}}(\theta)$ is the loglikelihood of the observations. Let $\shift: \Yset^\Zset\to \Yset^\Zset$ be the shift operator i.e., for all $\bfy\in\Yset^\Zset$ and all $s\in\Zset$, $\shift(\bfy)_s = \bfy_{s+1}$.
%\begin{assumptionA}
%\label{assum:transition:hmm}
%$\mathrm{inf}_{\theta\in\Theta}\mathrm{inf}_{x,x'\in\Xset} m_\theta(x,x') = \sigma_->0$ and $\mathrm{sup}_{\theta\in\Theta}\mathrm{sup}_{x,x'\in\Xset} m_\theta(x,x') = \sigma_+<\infty$. 
%\end{assumptionA}
%
%\begin{assumptionA}
%\label{assum:bound:likelihood}
%For all $y$, $\mathrm{inf}_{\theta\in\Theta}\int g_\theta^y(x)\mu(\rmd x) = c_-(y)>0$ and $\mathrm{sup}_{\theta\in\Theta}\int g_\theta^y(x) \mu(\rmd x) = c_+(y)<\infty$. 
%
%In addition, $\mathrm{sup}_{y\in\Yset} c_+(y)/c_-(y)<\infty$.
%\end{assumptionA}
%
%%\begin{assumptionA}
%%\label{assum:bound:likelihood:bis}
%%For all $y$, $\mathrm{inf}_{\theta\in\Theta}\mathrm{inf}_{x\in\Xset} g_\theta^y(x) = c_-(y)>0$ and $\mathrm{sup}_{\theta\in\Theta}\mathrm{sup}_{x\in\Xset} g_\theta^y(x)  = c_+(y)<\infty$. 
%%
%%In addition, $\mathrm{sup}_{y\in\Yset} c_+(y)/c_-(y)<\infty$.
%%\end{assumptionA}
%
%%\begin{assumptionA}
%%\label{assum:transition:hmm:bis}
%%For all $\theta\in\Theta$, there exist a transition kernel $K_\theta: \Xset\to \Yset$ and nonnegative measurable functions $\zeta_{-,\theta}$ and $\zeta_{+,\theta}$ defined on $\Yset$ such that for all $x\in\Xset$, $y\in\Yset$, all measurable set $A$,
%%$$
%%\zeta_{-,\theta}(y)K(y,A)\leq \int m_\theta (x,\rmd x')g_\theta^y(x') \1_{A}(x')\leq \zeta_{+,\theta}(y)K(y,A)\eqsp.
%%$$
%%\end{assumptionA}
%
%\begin{assumptionA}
%\label{assum:transition:variational}
%For all $t\geq 1$, $\mathrm{inf}_{\bfy\in\Yset^{\Zset}}\mathrm{inf}_{\phi\in\Phi}\mathrm{inf}_{x,x'\in\Xset} q^{\bfy}_{\phi,t-1|t}(x,x') = \varpi_->0$ and $\mathrm{sup}_{\bfy\in\Yset^{\Zset}}\mathrm{sup}_{\phi\in\Phi}\mathrm{sup}_{x,x'\in\Xset} q^{\bfy}_{\phi,t-1|t}(x,x') = \varpi_+<\infty$. 
%\end{assumptionA}
%
%\begin{assumptionA}
%\label{assum:variational:shift}
%For all $s\in \mathbb{Z}$, $\bfy\in\Yset^{\Zset}$, 
%$$
%q^{\bfy}_{\phi,s-1|s} = q^{\shift (\bfy)}_{\phi,s-2|s-1} \eqsp.
%$$
%\end{assumptionA}
%
%Note that under A\ref{assum:variational:shift}, the last term of the ELBO writes
%$$
%\frac{1}{t}\sum_{s=1}^t\mathbb{E}_{q^{\bfy}_{\varphi,0:t}}\left[\log \frac{b^{\bfy_{0:s-1}}_{\theta,s-1|s}(X_{s-1},X_s)}{q^{\bfy}_{\varphi,s-1|s}(X_{s-1},X_s)}\right]=\frac{1}{t}\sum_{s=1}^t\mathbb{E}_{q^{\bfy}_{\varphi,0:t}}\left[\log \frac{b^{\bfy_{0:s-1}}_{\theta,s-1|s}(X_{s-1},X_s)}{q^{\shift^s(\bfy)}_{\varphi,-1|0}(X_{s-1},X_s)}\right]\,.
%$$
%
%\textcolor{red}{
%\begin{itemize}
%\item Hypotheses pour stationnariser les noyaux backwards: ok.
%\item Oubli du filtre sous A1, A2: ok.
%\item Stationnarisation des esperances sous $q_\varphi$ lorsque $t$ temps vers l'infini:  ok (cf lemmes plus bas).
%\item Stationnarisation des vrais noyaux backwards $b^{\bfy_{0:s-1}}_{\theta,s-1|s}$: probleme restant ici, on a l'oubli du filtre et un controle de l'erreur en TV qui se propage a la TV entre les noyaux backwards mais dans la ELBO on a le log !
%\end{itemize}}


%\subsubsection*{Uniform forgetting of the filtering distribution}
%
%\begin{lemma}
%\label{lem:forgetting:filter}
%Assume that A\ref{assum:transition:hmm} and A\ref{assum:bound:likelihood} hold. For all bounded measurable functions  $h$, all $\theta\in\Theta$, all $0\leq s\leq t$, and all $1\leq u\leq s$, $m'<m\leq 0$,
%$$
%\left| \phi^{y_{m':s}}_{\theta,s|m',\chi}h - \phi^{y_{m:s}}_{\theta,s|m,\chi}h\right|\leq \left(1-\sigma_-/\sigma_+\right)^{s-m}\|h\|_\infty\,.
%$$
%\end{lemma}
%\begin{proof}
%This is a classical result under the strong mixing assumption A\ref{assum:transition:hmm} and the likelihood assumption A\ref{assum:bound:likelihood}. Consider the distribution
%$$
%\tilde \chi (\rmd x_m) \propto  \int \chi(\rmd x_{m'})g_\theta^{y_{m'}}(x_{m'})\left\{\prod_{u=m'+1}^{m-1} m_\theta(x_{u-1},x_u)g_\theta^{y_u}(x_u)\right\}m_\theta(x_{m-1},x_m)\rmd x_{m'+1:m}\,,
%$$
%so that $\phi^{y_{m':s}}_{\theta,s|m',\chi} = \phi^{y_{m:s}}_{\theta,s|m,\tilde\chi}$.
%This is a direct consequence of \cite[Corollary 1]{douc2004asymptotic} which states, under A\ref{assum:transition:hmm} and A\ref{assum:bound:likelihood},  that 
%$$
%\left\|\phi^{y_{m:s}}_{\theta,s|m,\tilde\chi}-\phi^{y_{m:s}}_{\theta,s|m,\chi}\right\|_{\mathrm{tv}}\leq \left(1-\sigma_-/\sigma_+\right)^{s-m}\,.
%$$
%\end{proof}
%By Lemma~\ref{lem:forgetting:filter}, for all $0\leq s\leq t$, $(\phi^{Y_{m:s}}_{\theta,s|m,\chi}h)_{m\leq s}$ is a uniform Cauchy sequence with respect to $\theta$ and $(\phi^{Y_{m:s}}_{\theta,s|m,\chi}h)_{m\leq s}$ converges uniformly a.s. The limit of this sequence is denoted by $(\phi^{Y_{-\infty:s}}_{\theta,s,\infty}h)_{m\leq s}$ and does not depend on $\chi$.
%
%
%\subsubsection*{Uniform forgetting of the variational smoothing distribution}
%\begin{lemma}
%\label{lem:forgetting:elbo}
%Assume that A\ref{assum:transition:variational} holds. For all bounded measurable functions  $h$, all $\theta\in\Theta$, $\varphi\in\Phi$, all $0\leq s\leq t$, and all $1\leq u\leq s$, 
%$$
%\left| \mathbb{E}_{q^{y_{0:t}}_{\varphi,0:t}}\left[h(X_{u-1},X_u)\right] - \mathbb{E}_{q^{y_{0:s}}_{\varphi,0:s}}\left[h(X_{u-1},X_u)\right]\right|\leq \left(1-\varpi_-/\varpi_+\right)^{s-u}\|h\|_\infty\,.
%$$
%\end{lemma}
%
%
%\begin{proof}
%Define the probability density function $q_{\varphi,s|t}$ by:
%$$
%q^{y_{0:t}}_{\varphi,s|t}: x_s \mapsto \int   \phi^{y_{0:t}}_{\varphi,t}(x_t)\prod_{r=s+1}^tq^{y_{0:r-1}}_{\varphi,r-1|r}(x_r,x_{r-1}) \rmd x_{s+1:t}\,,
%$$
%i.e. $q^{y_{0:t}}_{\varphi,s|t}$ is the marginal density of $X_s$ under $q^{y_{0:t}}_{\varphi,0:t}$. Then,
%$$
%\mathbb{E}_{q^{y_{0:t}}_{\varphi,0:t}}\left[h(X_{u-1},X_u)\right]  = \int q^{y_{0:t}}_{\varphi,s|t}(x_s)\prod_{r = u+1}^{s}q^{y_{0:r-1}}_{\varphi,r-1|r}(x_r,x_{r-1})  h(x_{u-1},x_u)\prod_{r = 1}^{u}q^{y_{0:r-1}}_{\varphi,r-1|r}(x_r,x_{r-1}) \rmd x_{0:s}\,.
%$$
%Therefore, under A\ref{assum:transition:variational},
%$$
%\left| \mathbb{E}_{q^{y_{0:t}}_{\varphi,0:t}}\left[h(X_{u-1},X_u)\right] - \mathbb{E}_{q^{y_{0:s}}_{\varphi,0:s}}\left[h(X_{u-1},X_u)\right]\right|\leq \left(1-\varpi_-/\varpi_+\right)^{s-u}\|\tilde h_{u}\|_\infty\,,
%$$
%where $\tilde h_{u}: x_{u}\mapsto \int  h(x_{u-1},x_u)\prod_{r = 1}^{u}q^{y_{0:r-1}}_{\varphi,r-1|r}(x_r,x_{r-1}) \rmd x_{0:u-1}$. The proof is completed by noting that
%$ \|\tilde h_{u}\|_\infty \leq \|h\|_\infty$.
%\end{proof}
%
%\begin{lemma}
%\label{lem:bound:filter}
%Assume that A\ref{assum:transition:hmm} and A\ref{assum:bound:likelihood} hold. For all $\theta\in\Theta$,  all $t\geq 0$, all $y_{0:t}$,
%$$
%\sigma_- c_-(y_t)/c_+(y_t)\leq \phi^{y_{0:t}}_{\theta,t}(x_{t})\leq \sigma_+ c_+(y_t)/c_-(y_t)\,.
%$$
%\end{lemma}
%\begin{proof}
%At time 0, we have $\phi^{y_{0}}_{\theta,0}(x_{0}) \propto \mu(x_0)g^{y_0}_\theta(x_0)$, so that $\sigma_- c_-(y_t)/c_+(y_t)\leq \phi^{y_{0}}_{\theta,0}(x_{0})\leq \sigma_+ c_+(y_t)/c_-(y_t)$. Similarly, 
%$$
%\phi^{y_{0:t}}_{\theta,t}(x_{t}) \propto g^{y_t}_\theta(x_t)\int \phi^{y_{0:t-1}}_{\theta,t-1}(x_{t-1})m_\theta(x_{t-1},x_t)\rmd x_{t-1}\,,
%$$
%so that $\sigma_- c_-(y_t)/c_+(y_t)\leq \phi^{y_{0:t}}_{\theta,t}(x_{t})\leq \sigma_+ c_+(y_t)/c_-(y_t)$.
%\end{proof}
%
%By Lemma~\ref{lem:forgetting:elbo} and Lemma~\ref{lem:bound:filter}, using that
%$$
%\left|\log \frac{b^{y_{0:s-1}}_{\theta,s-1|s}(x_{s-1},x_s)}{q^{y_{0:s-1}}_{\varphi,s-1|s}(x_{s-1},x_s)}\right|\leq \frac{\left|\log b^{y_{0:s-1}}_{\theta,s-1|s}(x_{s-1},x_s) - \log q^{y_{0:s-1}}_{\varphi,s-1|s}(x_{s-1},x_s)\right|}{b^{y_{0:s-1}}_{\theta,s-1|s}(x_{s-1},x_s)\wedge q^{y_{0:s-1}}_{\varphi,s-1|s}(x_{s-1},x_s)}\,,
%$$
%$\{\mathbb{E}_{q_{\varphi,0:t}}[\log b_{\theta,s-1|s}(X_{s-1},X_s)/q_{\varphi,s-1|s}(X_{s-1},X_s)]\}_{t\geq 1}$ is a uniform Cauchy sequence. Therefore, we can write
%$$
%\lim_{t\to\infty}\mathbb{E}_{q_{\varphi,0:t}}[\log b_{\theta,s-1|s}(X_{s-1},X_s)/q_{\varphi,s-1|s}(X_{s-1},X_s)] = \delta^{\theta,\varphi}_{\infty,s}(\mathsf{Y}_{0:\infty})\,,
%$$  uniformly almost surely.
%$\{\mathbb{E}_{q_{\varphi,0:t}}[\log b_{\theta,s-1|s}(X_{s-1},X_s)/q_{\varphi,s-1|s}(X_{s-1},X_s})]\}$

%\begin{lemma}
%\label{lem:bound:limit}
%Assume that A\ref{assum:transition:variational} holds. For all all $\theta\in\Theta$, $\varphi\in\Phi$, all $s\geq 0$, and all $1\leq u\leq s$,
%$$
%\left| \delta^{\theta,\varphi}_{\infty,s}(\mathsf{Y}_{0:\infty}) - \mathbb{E}_{q_{\varphi,0:s}}\left[\log \frac{b_{\theta,u-1|u}(X_{u-1},X_u)}{q_{\varphi,u-1|u}(X_{u-1},X_u)}\right] \right|\leq \left(1-\varpi_-/\varpi_+\right)^{s-u}\|h\|_\infty\,.
%$$
%\end{lemma}
%\begin{proof}
%By Lemma~\ref{lem:forgetting:elbo},
%$$
%\left| \mathbb{E}_{q_{\varphi,0:t}}\left[\log \frac{b_{\theta,u-1|u}(X_{u-1},X_u)}{q_{\varphi,u-1|u}(X_{u-1},X_u)}\right] - \mathbb{E}_{q_{\varphi,0:s}}\left[\log \frac{b_{\theta,u-1|u}(X_{u-1},X_u)}{q_{\varphi,u-1|u}(X_{u-1},X_u)}\right]\right|\leq \left(1-\varpi_-/\varpi_+\right)^{s-u}\|h\|_\infty\,.
%$$
%Then, when $t$ grows to $\infty$, this yields
%$$
%\left| \delta^{\theta,\varphi}_{\infty,u}(\mathsf{Y}_{0:\infty}) - \mathbb{E}_{q_{\varphi,0:s}}\left[\log \frac{b_{\theta,u-1|u}(X_{u-1},X_u)}{q_{\varphi,u-1|u}(X_{u-1},X_u)}\right]\right|\leq \left(1-\varpi_-/\varpi_+\right)^{s-u}\|h\|_\infty\,.
%$$
%\end{proof}
%Then,
%$$
%\sum_{s=1}^t\mathrm{sup}_{\theta\in\Theta}\mathrm{sup}_{\phi\in\Phi}\left|\mathbb{E}_{q_{\varphi,0:t}}\left[\log \frac{b_{\theta,s-1|s}(X_{s-1},X_s)}{q_{\varphi,s-1|s}(X_{s-1},X_s)}\right]- \delta^{\theta,\varphi}_{\infty,s}(\mathsf{Y}_{0:\infty})\right| \leq \frac{\varpi_+}{\varpi_-}\,. 
%$$
%Since $\delta^{\theta,\varphi}_{\infty,s}(\mathsf{Y}_{0:\infty})$ is integrable, the ergodic theorem implies that $\pi$-almost surely and in $\mathrm{L}^1(\pi)$,
%$$
%\lim_{t\to \infty}\frac{1}{t}\mathcal{L}(\theta,\varphi) = \mathbb{E}\left[\delta^{\theta,\varphi}_{\infty,s}(\mathsf{Y}_{0:\infty})\right]
%$$




%\begin{lemma}
%\label{lem:bound:limit}
%For all all $\theta\in\Theta$, $\varphi\in\Phi$, all $s\geq 0$, and all $1\leq u\leq s$,
%$$
%\left| \delta^{\theta,\varphi}_{\infty,s}(\mathsf{Y}_{0:\infty}) - - \mathbb{E}_{q_{\varphi,0:s}}\left[\log \frac{b_{\theta,u-1|u}(X_{u-1},X_u)}{q_{\varphi,u-1|u}(X_{u-1},X_u)}\right] \right|\leq \left(1-\varpi_-/\varpi_+\right)^{s-u}\|h\|_\infty\,.
%$$
%\end{lemma}
%\begin{proof}
%By Lemma~\ref{lem:forgetting:elbo},
%$$
%\left| \mathbb{E}_{q_{\varphi,0:t}}\left[\log \frac{b_{\theta,u-1|u}(X_{u-1},X_u)}{q_{\varphi,u-1|u}(X_{u-1},X_u)}\right] - \mathbb{E}_{q_{\varphi,0:s}}\left[\log \frac{b_{\theta,u-1|u}(X_{u-1},X_u)}{q_{\varphi,u-1|u}(X_{u-1},X_u)}\right]\right|\leq \left(1-\varpi_-/\varpi_+\right)^{s-u}\|h\|_\infty\,.
%$$
%Then, when $t$ grows to $\infty$, this yields
%$$
%\left| \delta^{\theta,\varphi}_{\infty,u}(\mathsf{Y}_{0:\infty}) - \mathbb{E}_{q_{\varphi,0:s}}\left[\log \frac{b_{\theta,u-1|u}(X_{u-1},X_u)}{q_{\varphi,u-1|u}(X_{u-1},X_u)}\right]\right|\leq \left(1-\varpi_-/\varpi_+\right)^{s-u}\|h\|_\infty\,.
%$$
%\end{proof}


\bibliographystyle{apalike}
\bibliography{variationalhmm}
 
\end{document}
